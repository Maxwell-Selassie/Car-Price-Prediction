{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5b880354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import mlflow\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8e234e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:c:/Users/Maxwe/ML Projects/Car-Price-Prediction-Model/notebooks/mlruns/2', creation_time=1768475636351, experiment_id='2', last_update_time=1768475636351, lifecycle_stage='active', name='data_analysis_experiment', tags={}>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"sqlite:///../mlflow.db\")\n",
    "mlflow.set_experiment(\"data_analysis_experiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a829b9a",
   "metadata": {},
   "source": [
    "# `Step 1: Load Data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6f9b7210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths\n",
    "DATA_PATH = Path(\"../data/raw/car_details.csv\")\n",
    "RESULTS_PATH = Path(\"../artifacts/results/\")\n",
    "if not RESULTS_PATH.exists():\n",
    "    RESULTS_PATH.mkdir(parents=True, exist_ok=True)\n",
    "PLOT_PATH = Path(\"../artifacts/plots/\")\n",
    "if not PLOT_PATH.exists():\n",
    "    PLOT_PATH.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7085b62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the csv file into the python environment as a pandas dataFrame\n",
    "def _load_data(data_source: str | Path = DATA_PATH) -> pd.DataFrame:\n",
    "    \"\"\" \n",
    "        Loads the data from csv file into the jupyter environment as a pandas dataframe\n",
    "\n",
    "        Args:\n",
    "            data_source: str|Path = Path to csv file\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame containing rows and columns\n",
    "\n",
    "        Raises:\n",
    "            FileNotFoundError: If file path is not found\n",
    "            ValueError: If dataframe is empty\n",
    "    \"\"\"\n",
    "    filepath = Path(data_source)\n",
    "    if not filepath.exists():\n",
    "        raise FileNotFoundError(f'File Not Found! Check filepath and try again')\n",
    "    \n",
    "    try:\n",
    "        print(f'Reading Data From CSV File...')\n",
    "        df = pd.read_csv(data_source) \n",
    "        print(f'Data successfully loaded with {len(df)} rows and {len(df.columns)} columns')\n",
    "\n",
    "        # log dataset and its relevant info in mlflow\n",
    "        dataset = mlflow.data.from_pandas(\n",
    "            df, filepath, name='car_price_details',targets=\"selling_price\"\n",
    "        )\n",
    "\n",
    "        # log shape of dataset\n",
    "        mlflow.log_params({\n",
    "        'n_rows' : len(df),\n",
    "        'n_columns' : len(df.columns)\n",
    "        })\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f'An error was encountered whiles trying to read data from CSV file : {e}')\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e5ecbf",
   "metadata": {},
   "source": [
    "# `Summary Stats of Numeric Columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e3f26823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numeric_summary_stats(df: pd.DataFrame, output_dir: str | Path = '../artifacts/results/') -> None:\n",
    "    \"\"\"\n",
    "        Short descriptive summary statistics of numeric columns\n",
    "        in the dataset and saves the results in a json file for\n",
    "        persistance and traceability,\n",
    "\n",
    "        Args: \n",
    "            df: pd.DataFrame\n",
    "            output_file: File path to save json data\n",
    "        \n",
    "        Example:\n",
    "            numeric_summary_stats(df,\"results/numeric_summary.json\")\n",
    "    \"\"\"\n",
    "    try:\n",
    "        output_file = f\"{output_dir}/numeric_summary.json\"\n",
    "        df.describe().to_json(output_file, indent=4)\n",
    "        print(f'Numeric descriptive stats saved to {output_file}')\n",
    "\n",
    "        mlflow.log_artifact(output_file)\n",
    "    except Exception as e:\n",
    "        print(f'An error occured whiles trying to save json data : {e}')\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b88a1106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_summary_data(df: pd.DataFrame, output_dir: str | Path = RESULTS_PATH) -> None:\n",
    "    \"\"\"  \n",
    "        Short descriptive summary statistcis of categorical columns\n",
    "        in the dataset and saves the result in a json file for\n",
    "        persistence and traceability\n",
    "\n",
    "        Args:\n",
    "            df: pd.DataFrame\n",
    "            output_file = File path to save json data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        output_file = f\"{output_dir}/categorical_summary.json\"\n",
    "        df.describe(exclude=[np.number]).to_json(output_file, indent=4)\n",
    "        print(f'Categorical descriptive stats saved to {output_file}')\n",
    "\n",
    "        mlflow.log_artifact(output_file)\n",
    "    except Exception as e:\n",
    "        print(f'An error occured whiles trying to save json data : {e}')\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda920b5",
   "metadata": {},
   "source": [
    "Definition of Columns\n",
    "- name - The model name of the car\n",
    "- fuel - The type of fuel used\n",
    "- seller type - Who's selling the car\n",
    "- transmission - The gear system of the car\n",
    "- owner - Ownership history\n",
    "- torque - rotational force of the engine\n",
    "- year - The manufacturing year of the car\n",
    "- selling_price - The selling price of the car\n",
    "- km_driven - The number of kilometres the car has been driven\n",
    "- mileage - the efficiency of the fuel\n",
    "- engine - engine displacement\n",
    "- max_power - maximum power output of the engine\n",
    "- seats - number of seats available in the car"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec193630",
   "metadata": {},
   "source": [
    "# `DATA QUALITY CHECKS`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f3863c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_data_quality_checks(df: pd.DataFrame, output_dir: str | Path = RESULTS_PATH) -> None:\n",
    "    \"\"\" \n",
    "        Perform multiple data quality checks on the dataframe\n",
    "        and prints the results to the console\n",
    "\n",
    "        Args:\n",
    "            df: pd.DataFrame\n",
    "            output_dir: str|Path = Directory to save results\n",
    "    \"\"\"\n",
    "    validation = {}\n",
    "    try:\n",
    "        print('Performing Data Quality Checks...\\n')\n",
    "\n",
    "        # check if dataframe is empty\n",
    "        if df.empty:\n",
    "            raise ValueError('DataFrame is empty!')\n",
    "        else:\n",
    "            print('DataFrame is not empty.')\n",
    "            validation['not_empty'] = True\n",
    "\n",
    "        # check if dataframe has mutliple rows and columns\n",
    "        if df.shape[0] < 2 or df.shape[1] < 2:\n",
    "            raise ValueError('DataFrame must have at least 2 rows and 2 columns!')\n",
    "        else:\n",
    "            print('DataFrame has multiple rows and columns.')\n",
    "            validation['has_multiple_rows_and_columns'] = True\n",
    "\n",
    "        # check for expected columns\n",
    "        expected_columns = ['name', 'year', 'selling_price', 'km_driven', 'fuel', 'seller_type', \n",
    "                            'transmission', 'owner', 'mileage', 'engine', 'max_power', 'torque', 'seats']\n",
    "        missing_columns = [col for col in expected_columns if col not in df.columns]\n",
    "        if missing_columns:\n",
    "            raise ValueError(f'Missing expected columns: {missing_columns}')    \n",
    "        else:\n",
    "            print('All expected columns are present.')\n",
    "            validation['expected_columns_present'] = True\n",
    "\n",
    "        # check for target column\n",
    "        target_column = 'selling_price'\n",
    "        if target_column not in df.columns:\n",
    "            raise ValueError(f'Target column \"{target_column}\" is missing!')\n",
    "        else:\n",
    "            print(f'Target column \"{target_column}\" is present.')\n",
    "            validation['target_column_present'] = True\n",
    "\n",
    "        # check for infinity values\n",
    "        if np.isinf(df.select_dtypes(include=[np.number])).values.any():\n",
    "            raise ValueError('DataFrame contains infinity values!')\n",
    "        else:\n",
    "            print('No infinity values found in DataFrame.')\n",
    "            validation['no_infinity_values'] = True\n",
    "\n",
    "        # check for negative values in numerical columns\n",
    "        numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        negative_value_columns = []\n",
    "        for col in numerical_cols:\n",
    "            if (df[col] < 0).any():\n",
    "                negative_value_columns.append(col)\n",
    "        if negative_value_columns:\n",
    "            raise ValueError(f'Numerical columns with negative values: {negative_value_columns}')\n",
    "        else:\n",
    "            print('No negative values found in numerical columns.')\n",
    "            validation['no_negative_values'] = True\n",
    "\n",
    "        # check for duplicate rows\n",
    "        duplicate_count = df.duplicated().sum()\n",
    "        if duplicate_count > 0:\n",
    "            print(f'Found {duplicate_count} duplicate rows in DataFrame!')\n",
    "            validation['no_duplicate_rows'] = False\n",
    "        else:\n",
    "            print('No duplicate rows found in DataFrame.')\n",
    "            validation['no_duplicate_rows'] = True\n",
    "        mlflow.log_param('duplicate_rows', duplicate_count)\n",
    "\n",
    "        # check for missing values\n",
    "        missing_value_count = df.isnull().sum().sum()\n",
    "        if missing_value_count > 0:\n",
    "            print(f'Found {missing_value_count} missing values in DataFrame!')\n",
    "            validation['no_missing_values'] = False\n",
    "        else:\n",
    "            print('No missing values found in DataFrame.')\n",
    "            validation['no_missing_values'] = True\n",
    "        mlflow.log_param('missing_values', missing_value_count)\n",
    "\n",
    "        # check for range of numerical columns\n",
    "        for col in numerical_cols:\n",
    "            col_min = df[col].min()\n",
    "            col_max = df[col].max()\n",
    "            print(f'Column \"{col}\" - Min: {col_min}, Max: {col_max}')\n",
    "            mlflow.log_param(f'{col}_min', col_min)\n",
    "            mlflow.log_param(f'{col}_max', col_max)\n",
    "        print('\\nData Quality Checks Completed Successfully.')\n",
    "        \n",
    "\n",
    "        output_file = f'{output_dir}/data_quality_checks.json'\n",
    "        with open(output_file, 'w') as f:\n",
    "            import json\n",
    "            json.dump(validation, f, indent=4)\n",
    "        print(f'Data quality check results saved to {output_file}')\n",
    "    except Exception as e:\n",
    "        print(f'An error occured during data quality checks: {e}')\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0ccf5317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing values check\n",
    "def missing_values_check(df: pd.DataFrame, output_dir: str | Path = RESULTS_PATH) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "        Check for missing values in the dataframe and return a summary dataframe\n",
    "        containing columns with missing values, number of missing values and percentage\n",
    "        of missing values.\n",
    "\n",
    "        Args:\n",
    "            df: pd.DataFrame\n",
    "            output_dir: str|Path = Directory to save the missing values summary\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Summary dataframe with missing values information\n",
    "    \"\"\"\n",
    "    missing_summary = df.isnull().sum()\n",
    "    if len( missing_summary[missing_summary > 0]) == 0:\n",
    "        print('No missing values found in the dataset.')\n",
    "        return pd.DataFrame(columns=['Missing Values', 'Percentage'])\n",
    "    \n",
    "    # log parameters to mlflow\n",
    "    mlflow.log_param('n_missing_columns', len(missing_summary[missing_summary > 0]))\n",
    "    missing_summary = missing_summary[missing_summary > 0]\n",
    "    missing_percentage = (missing_summary / len(df)) * 100\n",
    "    \n",
    "    missing_df = pd.DataFrame({\n",
    "        'Missing Values': missing_summary,\n",
    "        'Percentage': missing_percentage\n",
    "    })\n",
    "    artifact_path = f\"{output_dir}/missing_values_summary.csv\"\n",
    "    missing_df.to_csv(artifact_path)\n",
    "\n",
    "    mlflow.log_artifact(artifact_path)\n",
    "    return missing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d61225a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for duplicated data, keeping the first occurence\n",
    "def check_duplicates(df: pd.DataFrame) -> int:\n",
    "    \"\"\"\n",
    "        Check for duplicated rows in the dataframe.\n",
    "\n",
    "        Args:\n",
    "            df: pd.DataFrame\n",
    "\n",
    "        Returns:\n",
    "            int: Number of duplicated rows\n",
    "    \"\"\"\n",
    "    n_duplicates = df.duplicated(keep='first').sum() #returns duplicated rows, keeping only the first occurence\n",
    "    if n_duplicates > 0:\n",
    "        print(f'Found {n_duplicates} duplicated rows in the dataset.')\n",
    "    else:\n",
    "        print('No duplicated rows found in the dataset.')\n",
    "\n",
    "    mlflow.log_param('n_duplicated_rows', n_duplicates)\n",
    "    return n_duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a68b818a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling outliers using IQR method\n",
    "def handle_outliers_iqr(df: pd.DataFrame, column: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "        Handle outliers in a specified column using the IQR method.\n",
    "        Outliers are capped to the lower and upper bounds.\n",
    "\n",
    "        Args:\n",
    "            df: pd.DataFrame\n",
    "            column: str = Column name to handle outliers\n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame with outliers handled in the specified column\n",
    "    \"\"\"\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
    "    return {\n",
    "        'n_outliers': len(outliers),\n",
    "        'lower_bound': lower_bound,\n",
    "        'upper_bound': upper_bound\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3d542ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_summary(df: pd.DataFrame, output_dir: str | Path = RESULTS_PATH) -> None:\n",
    "    \"\"\"\n",
    "        Generate outlier summary for numerical columns and save to a json file.\n",
    "\n",
    "        Args:\n",
    "            df: pd.DataFrame\n",
    "            output_dir: str|Path = Directory to save the outlier summary\n",
    "    \"\"\"\n",
    "    outlier_info = {}\n",
    "    numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "    for col in numerical_cols:\n",
    "        outlier_data = handle_outliers_iqr(df, col)\n",
    "        outlier_info[col] = outlier_data\n",
    "\n",
    "    output_file = f\"{output_dir}/outlier_summary.json\"\n",
    "    try:\n",
    "        with open(output_file, 'w') as f:\n",
    "            import json\n",
    "            json.dump(outlier_info, f, indent=4)\n",
    "        print(f'Outlier summary saved to {output_file}')\n",
    "\n",
    "        mlflow.log_artifact(output_file)\n",
    "    except Exception as e:\n",
    "        print(f'An error occurred while trying to save outlier summary: {e}')\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0aa0db3",
   "metadata": {},
   "source": [
    "# `VISUALIZATIONS`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ea85c563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# univariate analysis for numeric columns\n",
    "def plot_numeric_distribution(df: pd.DataFrame, output_dir: str | Path = PLOT_PATH, save_plots: bool = True) -> None:\n",
    "    \"\"\"\n",
    "        Generate and save univariate analysis plots for numeric columns.\n",
    "\n",
    "        Args:\n",
    "            df: pd.DataFrame\n",
    "            output_dir: str|Path = Directory to save the plots\n",
    "            save_plots: bool = Whether to save the plots or display them\n",
    "    \"\"\"\n",
    "    numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    if not numerical_cols:\n",
    "        print('No numerical columns found for univariate analysis.')\n",
    "        return \n",
    "\n",
    "    n_cols = len(numerical_cols)\n",
    "    n_rows = (n_cols + 2) // 3  # Ceiling division\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5 * n_rows))\n",
    "    axes = axes.flatten() if n_cols > 1 else [axes]\n",
    "\n",
    "    for idx, col in enumerate(numerical_cols):\n",
    "            try:\n",
    "                sns.histplot(\n",
    "                    data=df,\n",
    "                    x=col,\n",
    "                    kde=True,\n",
    "                    ax=axes[idx],\n",
    "                    color='purple',\n",
    "                    alpha=0.7\n",
    "                )\n",
    "                axes[idx].set_title(f'Distribution of {col}', fontweight='bold')\n",
    "                axes[idx].set_ylabel('Frequency')\n",
    "                axes[idx].grid(True, alpha=0.3)\n",
    "            except Exception as e:\n",
    "                print(f'An error occurred while plotting {col}: {e}')\n",
    "                axes[idx].text(0.5, 0.5, f'Error: {str(e)[:50]}', \n",
    "                            ha='center', va='center', transform=axes[idx].transAxes)\n",
    "        \n",
    "    # Hide empty subplots\n",
    "    for idx in range(n_cols, len(axes)):\n",
    "            axes[idx].set_visible(False)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "        \n",
    "    if save_plots:\n",
    "            output_file = f\"{output_dir}/numeric_distributions.png\"\n",
    "            plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "            plt.close(fig)\n",
    "            print(f'Numeric distribution plots saved to {output_file}')\n",
    "    else:\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "799047c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# +1: strong positive correlation (as one increases, the other increases)\n",
    "# -1: strong negative correlation (as one increases, the other decreases)\n",
    "# 0: no correlation\n",
    "def plot_correlation_heatmap(df, method: str = 'spearman', plot_dir: str | Path = PLOT_PATH) -> None:\n",
    "    \"\"\"  \n",
    "    This function visualizes the relationship between numerical columns\n",
    "    through a correlation heatmap\n",
    "\n",
    "    Args:\n",
    "        method : whether to use a pearson or spearman method for correlation\n",
    "        plots_dir : file path to which plot will be saved\n",
    "\n",
    "    Raises:\n",
    "        An expection when an error is encountered during plotting and saving the plot\n",
    "    \"\"\"\n",
    "    numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    if len(numerical_cols) < 2:\n",
    "        print('Not enough numerical columns to plot correlation heatmap.')\n",
    "        raise ValueError('At least two numerical columns are required.')\n",
    "    \n",
    "    if len(df) < 2:\n",
    "        print('Not enough data to plot correlation heatmap.')\n",
    "        raise ValueError('At least two rows of data are required.')\n",
    "    \n",
    "    try:\n",
    "        corr = df[numerical_cols].corr(method=method)\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='coolwarm', square=True, cbar_kws={\"shrink\": .8})\n",
    "        plt.title(f'Correlation Heatmap ({method.capitalize()} Method)', fontsize=16, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        output_file = f\"{plot_dir}/correlation_heatmap_{method}.png\"\n",
    "        plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f'Correlation heatmap saved to {output_file}')\n",
    "        mlflow.log_artifact(output_file)    \n",
    "    except Exception as e:\n",
    "        print(f'An error occurred while plotting correlation heatmap: {e}')\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "87457be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# box plot visualization\n",
    "def plot_boxplots(df: pd.DataFrame, output_dir: str | Path = PLOT_PATH, save_plots: bool = True) -> None:\n",
    "    \"\"\"\n",
    "        Generate and save box plots for numerical columns.\n",
    "\n",
    "        Args:\n",
    "            df: pd.DataFrame\n",
    "            output_dir: str|Path = Directory to save the plots\n",
    "            save_plots: bool = Whether to save the plots or display them\n",
    "    \"\"\"\n",
    "    numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    if not numerical_cols:\n",
    "        print('No numerical columns found for box plot visualization.')\n",
    "        return \n",
    "\n",
    "    n_cols = len(numerical_cols)\n",
    "    n_rows = (n_cols + 2) // 3  # Ceiling division\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5 * n_rows))\n",
    "    axes = axes.flatten() if n_cols > 1 else [axes]\n",
    "\n",
    "    for idx, col in enumerate(numerical_cols):\n",
    "            try:\n",
    "                sns.boxplot(\n",
    "                    data=df,\n",
    "                    x=col,\n",
    "                    ax=axes[idx],\n",
    "                    color='lightblue'\n",
    "                )\n",
    "                axes[idx].set_title(f'Box Plot of {col}', fontweight='bold')\n",
    "                axes[idx].set_ylabel('Value')\n",
    "                axes[idx].grid(True, alpha=0.3)\n",
    "            except Exception as e:\n",
    "                print(f'An error occurred while plotting box plot for {col}: {e}')\n",
    "                axes[idx].text(0.5, 0.5, f'Error: {str(e)[:50]}', \n",
    "                            ha='center', va='center', transform=axes[idx].transAxes)\n",
    "        \n",
    "    # Hide empty subplots\n",
    "    for idx in range(n_cols, len(axes)):\n",
    "            axes[idx].set_visible(False)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "        \n",
    "    if save_plots:\n",
    "            output_file = f\"{output_dir}/numeric_boxplots.png\"\n",
    "            plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "            plt.close(fig)\n",
    "            print(f'Numeric box plots saved to {output_file}')\n",
    "    else:\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "67b7d2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot pie chart for categorical columns\n",
    "def plot_piechart_categorical(df: pd.DataFrame, column: str, output_dir: str | Path = PLOT_PATH, save_plots: bool = True) -> None:\n",
    "    \"\"\"\n",
    "        Generate and save pie chart for a categorical column.\n",
    "\n",
    "        Args:\n",
    "            df: pd.DataFrame\n",
    "            column: str = Categorical column to plot\n",
    "            output_dir: str|Path = Directory to save the plot\n",
    "            save_plots: bool = Whether to save the plot or display it\n",
    "    \"\"\"\n",
    "    if column not in df.columns:\n",
    "        print(f'Column \"{column}\" not found in DataFrame.')\n",
    "        return \n",
    "\n",
    "    try:\n",
    "        size = df[column].value_counts()\n",
    "        labels = df[column].unique()\n",
    "        colors = plt.cm.Paired.colors[:len(labels)]\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.title(f'Pie Chart of {column}', fontsize=16)\n",
    "        plt.pie(size, labels=labels, colors=colors, autopct='%2f%%', shadow=True, explode=[0.1]*len(labels))\n",
    "        \n",
    "        if save_plots:\n",
    "            output_file = f\"{output_dir}/pie_chart_{column}.png\"\n",
    "            plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            print(f'Pie chart for {column} saved to {output_file}')\n",
    "        else:\n",
    "            plt.show()\n",
    "    except Exception as e:\n",
    "        print(f'An error occurred while plotting pie chart for {column}: {e}')\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe82d80b",
   "metadata": {},
   "source": [
    "# `INFERENCE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d409f178",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence_interval(mean: float, std_dev: float, n: int, confidence: float = 0.95) -> tuple:\n",
    "    \"\"\"\n",
    "        Calculate the confidence interval for a given mean, standard deviation, and sample size.\n",
    "\n",
    "        Args:\n",
    "            mean: float = Sample mean\n",
    "            std_dev: float = Sample standard deviation\n",
    "            n: int = Sample size\n",
    "            confidence: float = Confidence level (default is 0.95)\n",
    "        Returns:\n",
    "            tuple: Lower and upper bounds of the confidence interval\n",
    "    \"\"\"\n",
    "    from scipy import stats\n",
    "    alpha = 1 - confidence\n",
    "    t_critical = stats.t.ppf(1 - alpha/2, df=n-1)\n",
    "    margin_of_error = t_critical * (std_dev / np.sqrt(n))\n",
    "    lower_bound = mean - margin_of_error\n",
    "    upper_bound = mean + margin_of_error\n",
    "    return (lower_bound, upper_bound)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ceb99d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_confidence_intervals(df: pd.DataFrame, column: str, output_dir: str | Path = PLOT_PATH, save_plots: bool = True) -> None:\n",
    "    \"\"\"\n",
    "        Generate and save confidence interval plot for a numerical column.\n",
    "\n",
    "        Args:\n",
    "            df: pd.DataFrame\n",
    "            column: str = Numerical column to plot\n",
    "            output_dir: str|Path = Directory to save the plot\n",
    "            save_plots: bool = Whether to save the plot or display it\n",
    "    \"\"\"\n",
    "    if column not in df.columns:\n",
    "        print(f'Column \"{column}\" not found in DataFrame.')\n",
    "        return \n",
    "\n",
    "    try:\n",
    "        mean = df[column].mean()\n",
    "        std_dev = df[column].std()\n",
    "        n = len(df[column])\n",
    "        lower_bound, upper_bound = confidence_interval(mean, std_dev, n)\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.errorbar(x=[0], y=[mean], yerr=[[mean - lower_bound], [upper_bound - mean]], fmt='o', color='blue', ecolor='lightgray', elinewidth=3, capsize=0)\n",
    "        plt.xlim(-1, 1)\n",
    "        plt.title(f'Confidence Interval for {column}', fontsize=16)\n",
    "        plt.ylabel(column)\n",
    "        plt.xticks([])\n",
    "\n",
    "        if save_plots:\n",
    "            output_file = f\"{output_dir}/confidence_interval_{column}.png\"\n",
    "            plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            print(f'Confidence interval plot for {column} saved to {output_file}')\n",
    "        else:\n",
    "            plt.show()\n",
    "    except Exception as e:\n",
    "        print(f'An error occurred while plotting confidence interval for {column}: {e}')\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4ca3f1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Data From CSV File...\n",
      "Data successfully loaded with 8128 rows and 13 columns\n",
      "Performing Data Quality Checks...\n",
      "\n",
      "DataFrame is not empty.\n",
      "DataFrame has multiple rows and columns.\n",
      "All expected columns are present.\n",
      "Target column \"selling_price\" is present.\n",
      "No infinity values found in DataFrame.\n",
      "No negative values found in numerical columns.\n",
      "Found 1202 duplicate rows in DataFrame!\n",
      "Found 1101 missing values in DataFrame!\n",
      "Column \"year\" - Min: 1983, Max: 2020\n",
      "Column \"selling_price\" - Min: 29999, Max: 10000000\n",
      "Column \"km_driven\" - Min: 1, Max: 2360457\n",
      "Column \"mileage\" - Min: 0.0, Max: 42.0\n",
      "Column \"engine\" - Min: 624.0, Max: 3604.0\n",
      "Column \"max_power\" - Min: 0.0, Max: 400.0\n",
      "Column \"seats\" - Min: 2.0, Max: 14.0\n",
      "\n",
      "Data Quality Checks Completed Successfully.\n",
      "Data quality check results saved to ..\\artifacts\\results/data_quality_checks.json\n",
      "Numeric descriptive stats saved to ../artifacts/results//numeric_summary.json\n",
      "Categorical descriptive stats saved to ..\\artifacts\\results/categorical_summary.json\n",
      "           Missing Values  Percentage\n",
      "mileage               221    2.718996\n",
      "engine                221    2.718996\n",
      "max_power             216    2.657480\n",
      "torque                222    2.731299\n",
      "seats                 221    2.718996\n",
      "Found 1202 duplicated rows in the dataset.\n",
      "Number of duplicated rows: 1202\n",
      "Outlier summary saved to ..\\artifacts\\results/outlier_summary.json\n",
      "Numeric distribution plots saved to ..\\artifacts\\plots/numeric_distributions.png\n",
      "Correlation heatmap saved to ..\\artifacts\\plots/correlation_heatmap_spearman.png\n",
      "Numeric box plots saved to ..\\artifacts\\plots/numeric_boxplots.png\n",
      "Pie chart for fuel saved to ..\\artifacts\\plots/pie_chart_fuel.png\n",
      "Pie chart for seller_type saved to ..\\artifacts\\plots/pie_chart_seller_type.png\n",
      "Pie chart for transmission saved to ..\\artifacts\\plots/pie_chart_transmission.png\n",
      "Pie chart for owner saved to ..\\artifacts\\plots/pie_chart_owner.png\n",
      "Confidence interval plot for year saved to ..\\artifacts\\plots/confidence_interval_year.png\n",
      "Confidence interval plot for selling_price saved to ..\\artifacts\\plots/confidence_interval_selling_price.png\n",
      "Confidence interval plot for km_driven saved to ..\\artifacts\\plots/confidence_interval_km_driven.png\n",
      "Confidence interval plot for mileage saved to ..\\artifacts\\plots/confidence_interval_mileage.png\n",
      "Confidence interval plot for engine saved to ..\\artifacts\\plots/confidence_interval_engine.png\n",
      "Confidence interval plot for max_power saved to ..\\artifacts\\plots/confidence_interval_max_power.png\n",
      "Confidence interval plot for seats saved to ..\\artifacts\\plots/confidence_interval_seats.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def main():\n",
    "    # load data\n",
    "    df = _load_data()\n",
    "    # Perform data quality checks\n",
    "    multiple_data_quality_checks(df)\n",
    "\n",
    "    # Generate numeric summary statistics\n",
    "    numeric_summary_stats(df)\n",
    "\n",
    "    # Generate categorical summary statistics\n",
    "    categorical_summary_data(df)\n",
    "\n",
    "    # Check for missing values\n",
    "    missing_values_df = missing_values_check(df)\n",
    "    print(missing_values_df)\n",
    "\n",
    "    # Check for duplicated rows\n",
    "    n_duplicates = check_duplicates(df)\n",
    "    print(f'Number of duplicated rows: {n_duplicates}')\n",
    "\n",
    "    # Generate outlier summary\n",
    "    outlier_summary(df)\n",
    "\n",
    "    # Plot numeric distributions\n",
    "    plot_numeric_distribution(df)\n",
    "\n",
    "    # Plot correlation heatmap\n",
    "    plot_correlation_heatmap(df, method='spearman')\n",
    "\n",
    "    # Plot box plots for numerical columns\n",
    "    plot_boxplots(df)\n",
    "\n",
    "    # Plot pie charts for categorical columns\n",
    "    categorical_cols = df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "    columns_to_exclude = ['name', 'torque']  # Add any columns you want to exclude from pie chart plotting\n",
    "    columns_to_plot = [col for col in categorical_cols if col not in columns_to_exclude]\n",
    "    for col in columns_to_plot:\n",
    "        plot_piechart_categorical(df, col)\n",
    "\n",
    "    # Plot confidence intervals for numerical columns\n",
    "    numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    for col in numerical_cols:\n",
    "        plot_confidence_intervals(df, col)\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
